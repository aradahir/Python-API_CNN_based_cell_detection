{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import os\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "THw_data = os.listdir('D:/cell_count/rawdata/THw/')\n",
    "THp_data = os.listdir('D:/cell_count/rawdata/THp/')\n",
    "CH_data = os.listdir('D:/cell_count/rawdata/CH/')\n",
    "CH_1_data = os.listdir('D:/cell_count/rawdata/CH_1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "for img in CH_data:\n",
    "    try:\n",
    "        img_read = plt.imread('D:/cell_count/rawdata/CH' + \"/\" + img)\n",
    "        img_resize = cv2.resize(img_read, (50, 50))\n",
    "        img_array = img_to_array(img_resize)\n",
    "        data.append(img_array)\n",
    "        labels.append(3)\n",
    "    except:\n",
    "        None\n",
    "\n",
    "for img in CH_1_data:\n",
    "    try:\n",
    "        img_read = plt.imread('D:/cell_count/rawdata/CH_1' + \"/\" + img)\n",
    "        img_resize = cv2.resize(img_read, (50, 50))\n",
    "        img_array = img_to_array(img_resize)\n",
    "        data.append(img_array)\n",
    "        labels.append(2)\n",
    "    except:\n",
    "        None\n",
    "\n",
    "for img in THw_data:\n",
    "    try:\n",
    "        img_read = plt.imread('D:/cell_count/rawdata/THw' + \"/\" + img)\n",
    "        img_resize = cv2.resize(img_read, (50, 50))\n",
    "        img_array = img_to_array(img_resize)\n",
    "        data.append(img_array)\n",
    "        labels.append(1)\n",
    "    except:\n",
    "        None\n",
    "        \n",
    "for img in THp_data:\n",
    "    try:\n",
    "        img_read = plt.imread('D:/cell_count/rawdata/THp' + \"/\" + img)\n",
    "        img_resize = cv2.resize(img_read, (50, 50))\n",
    "        img_array = img_to_array(img_resize)\n",
    "        data.append(img_array)\n",
    "        labels.append(0)\n",
    "    except:\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "idx = np.arange(image_data.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "image_data = image_data[idx]\n",
    "labels = labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(image_data, labels, test_size = 0.2, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes = 4)\n",
    "y_test = to_categorical(y_test, num_classes = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE OF TRAINING IMAGE DATA : (4448, 50, 50, 3)\n",
      "SHAPE OF TESTING IMAGE DATA : (1112, 50, 50, 3)\n",
      "SHAPE OF TRAINING LABELS : (4448, 4)\n",
      "SHAPE OF TESTING LABELS : (1112, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f'SHAPE OF TRAINING IMAGE DATA : {x_train.shape}')\n",
    "print(f'SHAPE OF TESTING IMAGE DATA : {x_test.shape}')\n",
    "print(f'SHAPE OF TRAINING LABELS : {y_train.shape}')\n",
    "print(f'SHAPE OF TESTING LABELS : {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Dense, Conv2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNNbuild(height, width, classes, channels):\n",
    "    model = Sequential()\n",
    "    \n",
    "    inputShape = (height, width, channels)\n",
    "    chanDim = -1\n",
    "    \n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        inputShape = (channels, height, width)\n",
    "    model.add(Conv2D(32, (3,3), activation = 'relu', input_shape = inputShape))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), activation = 'relu'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(32, (3,3), activation = 'relu'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(512, activation = 'relu'))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(classes, activation = 'softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_26 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 11, 11, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 9, 9, 32)          18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 4, 4, 32)          128       \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 305,124\n",
      "Trainable params: 303,844\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "height = 50\n",
    "width = 50\n",
    "classes = 4\n",
    "channels = 3\n",
    "model = CNNbuild(height = height, width = width, classes = classes, channels = channels)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4448/4448 [==============================] - 142s 32ms/step - loss: 1.1959 - acc: 0.5079\n",
      "Epoch 2/50\n",
      "4448/4448 [==============================] - 139s 31ms/step - loss: 0.9841 - acc: 0.5378\n",
      "Epoch 3/50\n",
      "4448/4448 [==============================] - 140s 32ms/step - loss: 0.9284 - acc: 0.5378\n",
      "Epoch 4/50\n",
      "4448/4448 [==============================] - 139s 31ms/step - loss: 0.8961 - acc: 0.5387\n",
      "Epoch 5/50\n",
      "4448/4448 [==============================] - 139s 31ms/step - loss: 0.8832 - acc: 0.5387\n",
      "Epoch 6/50\n",
      "4448/4448 [==============================] - 138s 31ms/step - loss: 0.8587 - acc: 0.5492\n",
      "Epoch 7/50\n",
      "4448/4448 [==============================] - 139s 31ms/step - loss: 0.8396 - acc: 0.5594\n",
      "Epoch 8/50\n",
      "4448/4448 [==============================] - 139s 31ms/step - loss: 0.8317 - acc: 0.5564\n",
      "Epoch 9/50\n",
      "4448/4448 [==============================] - 141s 32ms/step - loss: 0.8294 - acc: 0.5697\n",
      "Epoch 10/50\n",
      "4448/4448 [==============================] - 139s 31ms/step - loss: 0.8147 - acc: 0.5724\n",
      "Epoch 11/50\n",
      "4448/4448 [==============================] - 138s 31ms/step - loss: 0.8376 - acc: 0.5625\n",
      "Epoch 12/50\n",
      "4448/4448 [==============================] - 140s 31ms/step - loss: 0.8049 - acc: 0.5785\n",
      "Epoch 13/50\n",
      "4448/4448 [==============================] - 140s 31ms/step - loss: 0.8065 - acc: 0.5776\n",
      "Epoch 14/50\n",
      "4448/4448 [==============================] - 138s 31ms/step - loss: 0.8002 - acc: 0.5877\n",
      "Epoch 15/50\n",
      "4448/4448 [==============================] - 141s 32ms/step - loss: 0.7804 - acc: 0.5931\n",
      "Epoch 16/50\n",
      "4448/4448 [==============================] - 137s 31ms/step - loss: 0.7939 - acc: 0.5785\n",
      "Epoch 17/50\n",
      "4448/4448 [==============================] - 140s 32ms/step - loss: 0.8028 - acc: 0.5800\n",
      "Epoch 18/50\n",
      "4448/4448 [==============================] - 140s 31ms/step - loss: 0.7814 - acc: 0.5924\n",
      "Epoch 19/50\n",
      "4448/4448 [==============================] - 144s 32ms/step - loss: 0.7690 - acc: 0.5904\n",
      "Epoch 20/50\n",
      "4448/4448 [==============================] - 139s 31ms/step - loss: 0.7755 - acc: 0.5989\n",
      "Epoch 21/50\n",
      "4448/4448 [==============================] - 138s 31ms/step - loss: 0.7867 - acc: 0.5933\n",
      "Epoch 22/50\n",
      "4448/4448 [==============================] - 141s 32ms/step - loss: 0.7633 - acc: 0.6014\n",
      "Epoch 23/50\n",
      "4448/4448 [==============================] - 140s 31ms/step - loss: 0.7668 - acc: 0.6068\n",
      "Epoch 24/50\n",
      "4448/4448 [==============================] - 139s 31ms/step - loss: 0.7538 - acc: 0.6201\n",
      "Epoch 25/50\n",
      "4448/4448 [==============================] - 139s 31ms/step - loss: 0.7548 - acc: 0.6149\n",
      "Epoch 26/50\n",
      "4448/4448 [==============================] - 138s 31ms/step - loss: 0.7554 - acc: 0.6214\n",
      "Epoch 27/50\n",
      "4448/4448 [==============================] - 136s 31ms/step - loss: 0.7534 - acc: 0.6144\n",
      "Epoch 28/50\n",
      "4448/4448 [==============================] - 138s 31ms/step - loss: 0.7408 - acc: 0.6194\n",
      "Epoch 29/50\n",
      "4448/4448 [==============================] - 138s 31ms/step - loss: 0.7511 - acc: 0.6225\n",
      "Epoch 30/50\n",
      "4448/4448 [==============================] - 135s 30ms/step - loss: 0.7503 - acc: 0.6214\n",
      "Epoch 31/50\n",
      "4448/4448 [==============================] - 139s 31ms/step - loss: 0.7561 - acc: 0.6140\n",
      "Epoch 32/50\n",
      "4448/4448 [==============================] - 138s 31ms/step - loss: 0.7391 - acc: 0.6219\n",
      "Epoch 33/50\n",
      "4448/4448 [==============================] - 140s 32ms/step - loss: 0.7397 - acc: 0.6219\n",
      "Epoch 34/50\n",
      "4448/4448 [==============================] - 137s 31ms/step - loss: 0.7219 - acc: 0.6347\n",
      "Epoch 35/50\n",
      "4448/4448 [==============================] - 139s 31ms/step - loss: 0.7307 - acc: 0.6412\n",
      "Epoch 36/50\n",
      "4448/4448 [==============================] - 136s 31ms/step - loss: 0.7240 - acc: 0.6414\n",
      "Epoch 37/50\n",
      "4448/4448 [==============================] - 138s 31ms/step - loss: 0.7258 - acc: 0.6385\n",
      "Epoch 38/50\n",
      "4448/4448 [==============================] - 140s 31ms/step - loss: 0.6974 - acc: 0.6477\n",
      "Epoch 39/50\n",
      "4448/4448 [==============================] - 137s 31ms/step - loss: 0.7153 - acc: 0.6342\n",
      "Epoch 40/50\n",
      "4448/4448 [==============================] - 139s 31ms/step - loss: 0.7065 - acc: 0.6457\n",
      "Epoch 41/50\n",
      "4448/4448 [==============================] - 139s 31ms/step - loss: 0.7061 - acc: 0.6542\n",
      "Epoch 42/50\n",
      "4448/4448 [==============================] - 138s 31ms/step - loss: 0.6961 - acc: 0.6491\n",
      "Epoch 43/50\n",
      "4448/4448 [==============================] - 143s 32ms/step - loss: 0.6999 - acc: 0.6562\n",
      "Epoch 44/50\n",
      "4448/4448 [==============================] - 139s 31ms/step - loss: 0.6902 - acc: 0.6686\n",
      "Epoch 45/50\n",
      "4448/4448 [==============================] - 137s 31ms/step - loss: 0.6845 - acc: 0.6556\n",
      "Epoch 46/50\n",
      "4448/4448 [==============================] - 140s 31ms/step - loss: 0.6712 - acc: 0.6646\n",
      "Epoch 47/50\n",
      "4448/4448 [==============================] - 138s 31ms/step - loss: 0.6718 - acc: 0.6684\n",
      "Epoch 48/50\n",
      "4448/4448 [==============================] - 141s 32ms/step - loss: 0.6858 - acc: 0.6641\n",
      "Epoch 49/50\n",
      "4448/4448 [==============================] - 137s 31ms/step - loss: 0.6685 - acc: 0.6697\n",
      "Epoch 50/50\n",
      "4448/4448 [==============================] - 138s 31ms/step - loss: 0.6664 - acc: 0.6655\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(x_train, y_train, epochs = 50, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (30,) and (50,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-c49cc415fca9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Training Accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Taining Loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#ax1.set_xticks(np.arange(0, 31, 5))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of Epoch's\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2811\u001b[0m     return gca().plot(\n\u001b[0;32m   2812\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[1;32m-> 2813\u001b[1;33m         is not None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2815\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1803\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1804\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1805\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1807\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32m~\\Miniconda\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1601\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1603\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1604\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1605\u001b[0m             \u001b[0mlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    391\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 393\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 370\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'plot'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[1;32m--> 231\u001b[1;33m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (30,) and (50,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (18,8))\n",
    "plt.plot(range(0), h.history['acc'], label = 'Training Accuracy')\n",
    "plt.plot(range(30), h.history['loss'], label = 'Taining Loss')\n",
    "#ax1.set_xticks(np.arange(0, 31, 5))\n",
    "plt.xlabel(\"Number of Epoch's\")\n",
    "plt.ylabel('Accuracy/Loss Value')\n",
    "plt.title('Training Accuracy and Training Loss')\n",
    "plt.legend(loc = \"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1112/1112 [==============================] - 3s 2ms/step\n",
      "LOSS : 0.8344137668609619\n",
      "ACCURACY : 0.5593525182000167\n"
     ]
    }
   ],
   "source": [
    "predictions = model.evaluate(x_test, y_test)\n",
    "print(f'LOSS : {predictions[0]}')\n",
    "print(f'ACCURACY : {predictions[1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
